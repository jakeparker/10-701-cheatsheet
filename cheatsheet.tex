\documentclass[18pt,a3paper,landscape, ncols=3]{cheatsheet}
\usepackage[style=boxed]{preamble}

\usepackage{pdfpages}
\graphicspath{{graphics/}} % Sets the default location of pictures
\setkeys{Gin}{width=\linewidth,totalheight=\textheight,keepaspectratio} % Improves figure scaling

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Foundations
\section{Statisitcs} \seperator
	\subsection{LLN}
		\begin{mdframed}
		\end{mdframed}
	\subsection{Unbiasedness}
		\begin{mdframed}
		\end{mdframed}
	\subsection{Consistency}
		\begin{mdframed}
		\end{mdframed}
	\subsection{Hoeffding's Inequality}
		\begin{mdframed}
		\end{mdframed}
	\subsection{Chebyshev's Inequality}
		\begin{mdframed}
		\end{mdframed}
	\subsection{Properties of Gaussians}
		\begin{mdframed}
		\end{mdframed}
	\subsection{Bayes Rule} % why not
		\begin{mdframed}
			% posterior, likelihood, prior, marginal
			% unconditional version
			% conditional version
		\end{mdframed}
	\subsection{Conjugate Prior}
		\begin{mdframed}
			% common conjugate priors...
		\end{mdframed}
	
% Foundations
\section{Estimation} \seperator
	\subsection{MLE}
		\begin{mdframed}
		\end{mdframed}
	\subsection{MAP}
		\begin{mdframed}
		\end{mdframed}
	\subsection{Bayesian Estimation}
		\begin{mdframed}
		\end{mdframed}

% Foundations
\section{Learning Theory} \seperator
	\subsection{PAC}
		\begin{mdframed}
		\end{mdframed}
		
% Foundations
\section{Decision Theory} \seperator
	\subsection{Common Loss Functions}
		\begin{mdframed}
		\end{mdframed}
	\subsection{Bayes Risk}
		\begin{mdframed}
		\end{mdframed}
	\subsection{Bayes Optimal Rule}
		\begin{mdframed}
		\end{mdframed}
	\subsection{Emperical Risk Minimization}
		\begin{mdframed}
		\end{mdframed}

% Foundations
\section{Risk} \seperator
	\subsection{True Risk}
		\begin{mdframed}
		\end{mdframed}
	\subsection{Emperical Risk}
		\begin{mdframed}
		\end{mdframed}
	\subsection{Excess Risk}
		\begin{mdframed}
		\end{mdframed}
	\subsection{Structural Risk}
		\begin{mdframed}
		\end{mdframed}

	% Foundations
	\section{Risk Estimation}
		\subsection{Bias--Variance Tradeoff}
			\begin{mdframed}
				% bias =
				% variance = 
				% E[ (f(x) - f*(x))^2 ]  =  Bias^2 + Variance
				% ...
			\end{mdframed}
		\subsection{Hold--out Method}
			\begin{mdframed}
				% bias, variance tradeoff
			\end{mdframed}
		\subsection{K--Fold Cross--Validation}
			\begin{mdframed}
				% bias, variance tradeoff
			\end{mdframed}
		\subsection{LOO Cross--Validation}
			\begin{mdframed}
				% bias, variance tradeoff
			\end{mdframed}
		\subsection{Random Subsampling}
			\begin{mdframed}
				% bias, variance tradeoff
			\end{mdframed}

% Foundations
\section{Risk Minimization} \seperator
	\subsection{Emperical Risk Minimization}
		\begin{mdframed}
		\end{mdframed}
	\subsection{Structural Risk Minimization}
		\begin{mdframed}
		\end{mdframed}

% Foundations
\section{Overfitting} \seperator
	\begin{mdframed}
	\end{mdframed}

% Foundations
\section{Regularization} \seperator
	\subsection{Complexity Regularization}
		\begin{mdframed}
		\end{mdframed}
	\subsection{Information Criteria}
		\begin{mdframed}
		\end{mdframed}

% Foundations
\section{Model Selection} \seperator
	\begin{mdframed}
	\end{mdframed}

% Foundations
\section{Generalization Error} \seperator
	\subsection{Terms}
		\begin{mdframed}
		\end{mdframed}
	\subsection{True Risk Decomposition}
		\begin{mdframed}
			% estimation error
			% approximation error
			% Error vs Complexity Plot
		\end{mdframed}

% Parametric Models
\section{Regression} \seperator
	\subsection{Linear Regression}
		\begin{mdframed}
		\end{mdframed}
	\subsection{Ridge Regression}
		\begin{mdframed}
		\end{mdframed}
	\subsection{Lasso Regression}
		\begin{mdframed}
		\end{mdframed}
	\subsection{Polynomial Regression}
		\begin{mdframed}
		\end{mdframed}

% Parametric Models
\section{Classification} \seperator
	\subsection{Logistic Regression}
		\begin{mdframed}
			% basis functions
			% nonlinear features
			% ...
		\end{mdframed}
	\subsection{Naive Bayes}
		\begin{mdframed}
		\end{mdframed}
	\subsection{Boosting}
		\begin{mdframed}
		\end{mdframed}
	\subsection{Decision Trees}
		\begin{mdframed}
		\end{mdframed}
	\subsection{Support Vector Machines}
		\begin{mdframed}
		\end{mdframed}

% Parametric Models
\section{Deep Learning} \seperator
	\subsection{Common Activation Functions}
		\begin{mdframed}
		\end{mdframed}
	\subsection{Backpropagation}
		\begin{mdframed}
		\end{mdframed}
	\subsection{Gradient Descent}
		\begin{mdframed}
		\end{mdframed}
	\subsection{Perceptron}
		\begin{mdframed}
		\end{mdframed}
	\subsection{MLP}
		\begin{mdframed}
		\end{mdframed}
	\subsection{CNN}
		\begin{mdframed}
		\end{mdframed}
	\subsection{RNN}
		\begin{mdframed}
		\end{mdframed}
	\subsection{LSTM}
		\begin{mdframed}
		\end{mdframed}

% Non--Parametric Models
\section{Clustering} \seperator % Supervised Learning
	\subsection{KNN}
		\begin{mdframed}
		\end{mdframed}
	\subsection{Kernel Regression}
		\begin{mdframed}
		\end{mdframed}
	\subsection{Kernel Trick}
		\begin{mdframed}
		\end{mdframed}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\end{document}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
